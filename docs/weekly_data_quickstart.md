# å‘¨çº¿æ•°æ®ç³»ç»Ÿå¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
2. [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
3. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
4. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
5. [ç›¸å…³æ–‡æ¡£](#ç›¸å…³æ–‡æ¡£)

## ç³»ç»Ÿæ¦‚è¿°

å‘¨çº¿æ•°æ®ç³»ç»ŸåŸºäºå·²æœ‰çš„æ—¥çº¿æ•°æ®ï¼Œè‡ªåŠ¨ç”Ÿæˆå‘¨çº¿Kçº¿æ•°æ®ï¼Œç”¨äºæŠ€æœ¯åˆ†æå’Œå›¾è¡¨å±•ç¤ºã€‚

**æ ¸å¿ƒç‰¹æ€§**:
- âœ… åŸºäºæ—¥çº¿æ•°æ®è‡ªåŠ¨ç”Ÿæˆï¼Œæ— éœ€å¤–éƒ¨API
- âœ… æ¯å‘¨è‡ªåŠ¨æ›´æ–°ï¼Œæ— éœ€äººå·¥å¹²é¢„
- âœ… æ”¯æŒå†å²æ•°æ®æ‰¹é‡ç”Ÿæˆ
- âœ… æä¾›å®Œæ•´çš„APIæ¥å£

## ç¯å¢ƒå‡†å¤‡

### 1. ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Windows / Linux / macOS
- **Python**: 3.8+
- **æ•°æ®åº“**: PostgreSQL 12+

### 2. ä¾èµ–åŒ…

ç¡®ä¿å·²å®‰è£…ä»¥ä¸‹PythonåŒ…ï¼š

```bash
pip install pandas sqlalchemy psycopg2-binary
```

### 3. æ•°æ®åº“é…ç½®

åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®æ•°æ®åº“è¿æ¥ï¼š

```ini
DB_TYPE=postgresql
DB_HOST=192.168.31.237
DB_PORT=5446
DB_NAME=stock_analysis
DB_USER=postgres
DB_PASSWORD=qidianspacetime
```

### 4. æ•°æ®å‡†å¤‡

ç¡®ä¿ `historical_quotes` è¡¨ä¸­å·²æœ‰æ—¥çº¿æ•°æ®ã€‚å¯ä»¥é€šè¿‡ä»¥ä¸‹SQLæ£€æŸ¥ï¼š

```sql
SELECT COUNT(*) FROM historical_quotes;
SELECT MIN(date), MAX(date) FROM historical_quotes;
```

## å¿«é€Ÿå¼€å§‹

### æ­¥éª¤1: æµ‹è¯•æ•°æ®åº“è¿æ¥

```bash
python -c "from backend_core.database.db import SessionLocal; print('æ•°æ®åº“è¿æ¥æˆåŠŸ'); SessionLocal()"
```

å¦‚æœçœ‹åˆ°"æ•°æ®åº“è¿æ¥æˆåŠŸ"ï¼Œè¯´æ˜é…ç½®æ­£ç¡®ã€‚

### æ­¥éª¤2: æµ‹è¯•æ¨¡å¼è¿è¡Œ

é¦–æ¬¡ä½¿ç”¨å»ºè®®å…ˆè¿è¡Œæµ‹è¯•æ¨¡å¼ï¼Œåªå¤„ç†å‰5åªè‚¡ç¥¨ï¼š

```bash
cd e:\wangxw\work\stock_quote_analayze
python backend_core/data_collectors/akshare/weekly_collector.py 2025-01-01 2025-11-30 --test
```

**é¢„æœŸè¾“å‡º**:
```
2025-11-30 15:00:00,000 - INFO - å¼€å§‹ç”Ÿæˆå‘¨çº¿æ•°æ®: 2025-01-01 åˆ° 2025-11-30
2025-11-30 15:00:01,000 - INFO - å‡†å¤‡å¤„ç† 5 åªè‚¡ç¥¨
2025-11-30 15:00:05,000 - INFO - å‘¨çº¿æ•°æ®ç”Ÿæˆå®Œæˆ: {'total': 5, 'success': 5, 'failed': 0, 'generated_rows': 50}
```

### æ­¥éª¤3: éªŒè¯ç”Ÿæˆçš„æ•°æ®

ä½¿ç”¨SQLæŸ¥è¯¢éªŒè¯æ•°æ®æ˜¯å¦æ­£ç¡®ç”Ÿæˆï¼š

```sql
-- æŸ¥çœ‹ç”Ÿæˆçš„å‘¨çº¿æ•°æ®æ€»æ•°
SELECT COUNT(*) FROM weekly_quotes;

-- æŸ¥çœ‹æŸåªè‚¡ç¥¨çš„å‘¨çº¿æ•°æ®
SELECT * FROM weekly_quotes 
WHERE code = '000001' 
ORDER BY date DESC 
LIMIT 10;

-- æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
SELECT 
    COUNT(DISTINCT code) as stock_count,
    MIN(date) as earliest_week,
    MAX(date) as latest_week,
    COUNT(*) as total_weeks
FROM weekly_quotes;
```

### æ­¥éª¤4: ç”Ÿæˆå®Œæ•´å†å²æ•°æ®

æµ‹è¯•é€šè¿‡åï¼Œç”Ÿæˆæ‰€æœ‰è‚¡ç¥¨çš„å‘¨çº¿æ•°æ®ï¼š

```bash
# ç”Ÿæˆ2025å¹´çš„å‘¨çº¿æ•°æ®
python backend_core/data_collectors/akshare/weekly_collector.py 2025-01-01 2025-11-30

# æˆ–è€…ç”Ÿæˆæ›´é•¿æ—¶é—´èŒƒå›´çš„æ•°æ®
python backend_core/data_collectors/akshare/weekly_collector.py 2020-01-01 2025-11-30
```

**æ³¨æ„**: 
- é¦–æ¬¡ç”Ÿæˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆå–å†³äºè‚¡ç¥¨æ•°é‡å’Œæ—¶é—´èŒƒå›´ï¼‰
- å»ºè®®ä»è¿‘æœŸæ•°æ®å¼€å§‹ï¼Œé€æ­¥æ‰©å±•åˆ°å†å²æ•°æ®

### æ­¥éª¤5: å¯åŠ¨å®šæ—¶ä»»åŠ¡

å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨ï¼Œå®ç°æ¯å‘¨è‡ªåŠ¨æ›´æ–°ï¼š

```bash
python -m backend_core.data_collectors.main
```

å®šæ—¶ä»»åŠ¡ä¼šåœ¨æ¯å‘¨å…­å‡Œæ™¨1ç‚¹è‡ªåŠ¨ç”Ÿæˆæœ€æ–°çš„å‘¨çº¿æ•°æ®ã€‚

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: ç”ŸæˆæŒ‡å®šè‚¡ç¥¨çš„å‘¨çº¿æ•°æ®

```bash
python backend_core/data_collectors/akshare/weekly_collector.py 2025-01-01 2025-11-30 --stocks 000001 600000 000002
```

### ç¤ºä¾‹2: æŸ¥è¯¢å‘¨çº¿æ•°æ®

```python
from backend_core.database.db import SessionLocal
from sqlalchemy import text

session = SessionLocal()

# æŸ¥è¯¢æŸåªè‚¡ç¥¨çš„å‘¨çº¿æ•°æ®
query = text("""
    SELECT date, open, high, low, close, volume, change_percent
    FROM weekly_quotes
    WHERE code = :code
    ORDER BY date DESC
    LIMIT 20
""")

result = session.execute(query, {'code': '000001'})
for row in result:
    print(f"æ—¥æœŸ: {row[0]}, å¼€ç›˜: {row[1]}, æ”¶ç›˜: {row[4]}, æ¶¨è·Œå¹…: {row[6]}%")

session.close()
```

### ç¤ºä¾‹3: é€šè¿‡APIè·å–å‘¨çº¿æ•°æ®

```bash
# å¯åŠ¨APIæœåŠ¡
python start_backend_api.py

# è°ƒç”¨API
curl "http://localhost:5000/api/quotes/weekly/000001?start_date=2025-01-01&end_date=2025-11-30"
```

## å¸¸è§é—®é¢˜

### Q1: æ•°æ®åº“è¿æ¥å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: `Connection refused (0x0000274D/10061)`

**è§£å†³æ–¹æ³•**:
1. æ£€æŸ¥PostgreSQLæœåŠ¡æ˜¯å¦è¿è¡Œ
2. éªŒè¯æ•°æ®åº“é…ç½®ï¼ˆä¸»æœºã€ç«¯å£ã€ç”¨æˆ·åã€å¯†ç ï¼‰
3. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®

```bash
# Windowsæ£€æŸ¥PostgreSQLæœåŠ¡
sc query postgresql-x64-12

# å¯åŠ¨æœåŠ¡
sc start postgresql-x64-12
```

### Q2: æ²¡æœ‰ç”Ÿæˆæ•°æ®

**å¯èƒ½åŸå› **:
1. æ—¥çº¿æ•°æ®ä¸å­˜åœ¨
2. æ—¥æœŸèŒƒå›´å†…æ²¡æœ‰äº¤æ˜“æ•°æ®

**è§£å†³æ–¹æ³•**:
```sql
-- æ£€æŸ¥æ—¥çº¿æ•°æ®
SELECT COUNT(*) FROM historical_quotes WHERE code = '000001';

-- æ£€æŸ¥æ—¥æœŸèŒƒå›´
SELECT MIN(date), MAX(date) FROM historical_quotes WHERE code = '000001';
```

### Q3: æ¶¨è·Œå¹…ä¸ºNULL

**åŸå› **: ç¬¬ä¸€å‘¨çš„æ•°æ®æ— æ³•è®¡ç®—æ¶¨è·Œå¹…ï¼ˆç¼ºå°‘ä¸Šä¸€å‘¨çš„æ”¶ç›˜ä»·ï¼‰

**è¿™æ˜¯æ­£å¸¸ç°è±¡**ï¼Œå¯ä»¥å¿½ç•¥æˆ–åœ¨æŸ¥è¯¢æ—¶è¿‡æ»¤ï¼š

```sql
SELECT * FROM weekly_quotes 
WHERE code = '000001' 
  AND change_percent IS NOT NULL
ORDER BY date DESC;
```

### Q4: ç”Ÿæˆé€Ÿåº¦æ…¢

**ä¼˜åŒ–å»ºè®®**:
1. ç¼©å°æ—¥æœŸèŒƒå›´ï¼Œåˆ†æ‰¹ç”Ÿæˆ
2. ä½¿ç”¨ `--stocks` å‚æ•°åªç”Ÿæˆéƒ¨åˆ†è‚¡ç¥¨
3. æ£€æŸ¥æ•°æ®åº“æ€§èƒ½ï¼Œæ·»åŠ ç´¢å¼•

```sql
-- æ·»åŠ ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
CREATE INDEX IF NOT EXISTS idx_historical_quotes_code_date 
ON historical_quotes(code, date);

CREATE INDEX IF NOT EXISTS idx_weekly_quotes_code_date 
ON weekly_quotes(code, date);
```

### Q5: å¦‚ä½•é‡æ–°ç”Ÿæˆæ•°æ®

å¦‚æœéœ€è¦é‡æ–°ç”ŸæˆæŸåªè‚¡ç¥¨çš„å‘¨çº¿æ•°æ®ï¼š

```sql
-- åˆ é™¤æ—§æ•°æ®
DELETE FROM weekly_quotes WHERE code = '000001';

-- é‡æ–°ç”Ÿæˆ
python backend_core/data_collectors/akshare/weekly_collector.py 2025-01-01 2025-11-30 --stocks 000001
```

æˆ–è€…ç›´æ¥è¿è¡Œï¼ˆä¼šè‡ªåŠ¨è¦†ç›–ï¼‰ï¼š

```bash
python backend_core/data_collectors/akshare/weekly_collector.py 2025-01-01 2025-11-30 --stocks 000001
```

## æ•°æ®éªŒè¯

### éªŒè¯å‘¨çº¿æ•°æ®çš„æ­£ç¡®æ€§

```python
import pandas as pd
from backend_core.database.db import SessionLocal
from sqlalchemy import text

def validate_weekly_data(stock_code, week_date):
    """éªŒè¯æŸä¸€å‘¨çš„æ•°æ®æ˜¯å¦æ­£ç¡®"""
    session = SessionLocal()
    
    # è·å–å‘¨çº¿æ•°æ®
    weekly_query = text("""
        SELECT date, open, high, low, close, volume, amount
        FROM weekly_quotes
        WHERE code = :code AND date = :date
    """)
    weekly = session.execute(weekly_query, {
        'code': stock_code,
        'date': week_date
    }).fetchone()
    
    # è·å–è¯¥å‘¨çš„æ—¥çº¿æ•°æ®
    # å‡è®¾week_dateæ˜¯å‘¨äº”ï¼Œå‘å‰æ¨7å¤©
    week_start = pd.to_datetime(week_date) - pd.Timedelta(days=6)
    daily_query = text("""
        SELECT date, open, high, low, close, volume, amount
        FROM historical_quotes
        WHERE code = :code 
          AND date >= :start_date 
          AND date <= :end_date
        ORDER BY date ASC
    """)
    daily_data = session.execute(daily_query, {
        'code': stock_code,
        'start_date': week_start.strftime('%Y-%m-%d'),
        'end_date': week_date
    }).fetchall()
    
    if not daily_data:
        print(f"è¯¥å‘¨æ²¡æœ‰æ—¥çº¿æ•°æ®")
        return
    
    # éªŒè¯
    print(f"å‘¨çº¿æ•°æ®: {weekly}")
    print(f"æ—¥çº¿æ•°æ®æ¡æ•°: {len(daily_data)}")
    print(f"å‘¨å¼€ç›˜åº”ä¸º: {daily_data[0][1]} (å®é™…: {weekly[1]})")
    print(f"å‘¨æ”¶ç›˜åº”ä¸º: {daily_data[-1][4]} (å®é™…: {weekly[4]})")
    print(f"å‘¨æœ€é«˜åº”ä¸º: {max(d[2] for d in daily_data)} (å®é™…: {weekly[2]})")
    print(f"å‘¨æœ€ä½åº”ä¸º: {min(d[3] for d in daily_data)} (å®é™…: {weekly[3]})")
    print(f"å‘¨æˆäº¤é‡åº”ä¸º: {sum(d[5] for d in daily_data)} (å®é™…: {weekly[5]})")
    
    session.close()

# ä½¿ç”¨ç¤ºä¾‹
validate_weekly_data('000001', '2025-11-28')
```

## ç›‘æ§ä¸ç»´æŠ¤

### æŸ¥çœ‹ç”Ÿæˆæ—¥å¿—

```bash
# æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶
tail -f weekly_generation.log

# æˆ–åœ¨Windowsä¸Š
type weekly_generation.log
```

### æŸ¥çœ‹æ“ä½œè®°å½•

```sql
SELECT * FROM historical_collect_operation_logs
WHERE operation_type = 'generate_weekly_from_daily'
ORDER BY created_at DESC
LIMIT 10;
```

### å®šæœŸæ£€æŸ¥æ•°æ®å®Œæ•´æ€§

å»ºè®®æ¯æœˆè¿è¡Œä¸€æ¬¡æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ï¼š

```sql
-- æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„å‘¨
WITH RECURSIVE weeks AS (
    SELECT DATE '2025-01-05' AS week_date  -- ç¬¬ä¸€ä¸ªå‘¨äº”
    UNION ALL
    SELECT week_date + INTERVAL '7 days'
    FROM weeks
    WHERE week_date < CURRENT_DATE
)
SELECT w.week_date, COUNT(q.date) as stock_count
FROM weeks w
LEFT JOIN weekly_quotes q ON w.week_date = q.date
GROUP BY w.week_date
HAVING COUNT(q.date) < 5000  -- å‡è®¾æœ‰5000åªè‚¡ç¥¨
ORDER BY w.week_date DESC;
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹é‡ç”Ÿæˆç­–ç•¥

å¯¹äºå¤§é‡å†å²æ•°æ®ï¼Œå»ºè®®åˆ†æ‰¹ç”Ÿæˆï¼š

```bash
# æŒ‰å¹´ä»½åˆ†æ‰¹
python weekly_collector.py 2020-01-01 2020-12-31
python weekly_collector.py 2021-01-01 2021-12-31
python weekly_collector.py 2022-01-01 2022-12-31
python weekly_collector.py 2023-01-01 2023-12-31
python weekly_collector.py 2024-01-01 2024-12-31
python weekly_collector.py 2025-01-01 2025-11-30
```

### 2. æ•°æ®åº“ä¼˜åŒ–

```sql
-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_historical_quotes_code_date ON historical_quotes(code, date);
CREATE INDEX idx_weekly_quotes_date ON weekly_quotes(date);

-- å®šæœŸæ¸…ç†å’Œä¼˜åŒ–
VACUUM ANALYZE weekly_quotes;
VACUUM ANALYZE historical_quotes;
```

### 3. å¹¶å‘å¤„ç†

å¦‚æœéœ€è¦æ›´å¿«çš„å¤„ç†é€Ÿåº¦ï¼Œå¯ä»¥ä¿®æ”¹ä»£ç æ”¯æŒå¤šè¿›ç¨‹ï¼š

```python
from multiprocessing import Pool

def generate_for_stocks_batch(stock_codes):
    generator = WeeklyDataGenerator()
    return generator.generate_weekly_data(start_date, end_date, stock_codes)

# å°†è‚¡ç¥¨åˆ—è¡¨åˆ†æˆå¤šä¸ªæ‰¹æ¬¡
batch_size = 100
stock_batches = [stocks[i:i+batch_size] for i in range(0, len(stocks), batch_size)]

# å¹¶å‘å¤„ç†
with Pool(processes=4) as pool:
    results = pool.map(generate_for_stocks_batch, stock_batches)
```

## ç›¸å…³æ–‡æ¡£

- ğŸ“˜ [ç³»ç»Ÿè®¾è®¡æ–‡æ¡£](./weekly_data_design.md) - è¯¦ç»†çš„æŠ€æœ¯è®¾è®¡
- ğŸ“— [APIæ¥å£æ–‡æ¡£](./weekly_data_api.md) - APIä½¿ç”¨è¯´æ˜
- ğŸ“™ [å®æ–½æ€»ç»“æ–‡æ¡£](./weekly_data_implementation.md) - å®æ–½ç»†èŠ‚

## æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ `weekly_generation.log`
2. æ£€æŸ¥æ•°æ®åº“è¿æ¥å’Œæ•°æ®å®Œæ•´æ€§
3. å‚è€ƒå¸¸è§é—®é¢˜éƒ¨åˆ†
4. æŸ¥é˜…ç›¸å…³è®¾è®¡æ–‡æ¡£

---

**æœ€åæ›´æ–°**: 2025-11-30  
**ç‰ˆæœ¬**: 1.0.0
