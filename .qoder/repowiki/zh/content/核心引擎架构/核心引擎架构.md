# 核心引擎架构

<cite>
**本文档引用的文件**
- [realtime.py](file://backend_core/data_collectors/akshare/realtime.py)
- [historical.py](file://backend_core/data_collectors/akshare/historical.py)
- [daily_report_scheduler.py](file://backend_core/scheduler/daily_report_scheduler.py)
- [news_scheduler.py](file://backend_core/schedulers/news_scheduler.py)
- [historical_quotes.py](file://backend_core/models/historical_quotes.py)
- [watchlist.py](file://backend_core/models/watchlist.py)
- [config.py](file://backend_core/config/config.py)
- [db.py](file://backend_core/database/db.py)
- [base.py](file://backend_core/data_collectors/akshare/base.py)
- [tushare/realtime.py](file://backend_core/data_collectors/tushare/realtime.py)
- [tushare/historical.py](file://backend_core/data_collectors/tushare/historical.py)
- [main.py](file://backend_core/data_collectors/main.py)
</cite>

## 目录
1. [项目结构](#项目结构)
2. [数据采集器实现](#数据采集器实现)
3. [定时任务调度机制](#定时任务调度机制)
4. [核心数据模型](#核心数据模型)
5. [配置注入机制](#配置注入机制)
6. [与backend_api的集成](#与backend_api的集成)
7. [数据采集失败处理与重试机制](#数据采集失败处理与重试机制)
8. [性能监控实现](#性能监控实现)

## 项目结构

backend_core股票分析核心引擎采用模块化设计，主要包含以下几个核心目录：

- **data_collectors**: 数据采集器模块，包含基于AkShare和Tushare的数据采集实现
- **scheduler** 和 **schedulers**: 定时任务调度模块
- **models**: 核心数据模型定义
- **config**: 配置管理模块
- **database**: 数据库连接和管理模块

```mermaid
graph TD
subgraph "backend_core"
subgraph "数据采集"
data_collectors[data_collectors]
akshare[akshare]
tushare[tushare]
end
subgraph "调度"
scheduler[scheduler]
schedulers[schedulers]
end
subgraph "模型"
models[models]
end
subgraph "配置"
config[config]
end
subgraph "数据库"
database[database]
end
end
data_collectors --> akshare
data_collectors --> tushare
data_collectors --> main[main.py]
scheduler --> daily_report_scheduler[daily_report_scheduler.py]
schedulers --> news_scheduler[news_scheduler.py]
config --> config_py[config.py]
database --> db[db.py]
models --> historical_quotes[historical_quotes.py]
models --> watchlist[watchlist.py]
```

**图示来源**
- [realtime.py](file://backend_core/data_collectors/akshare/realtime.py)
- [historical.py](file://backend_core/data_collectors/akshare/historical.py)
- [daily_report_scheduler.py](file://backend_core/scheduler/daily_report_scheduler.py)
- [news_scheduler.py](file://backend_core/schedulers/news_scheduler.py)
- [historical_quotes.py](file://backend_core/models/historical_quotes.py)
- [watchlist.py](file://backend_core/models/watchlist.py)
- [config.py](file://backend_core/config/config.py)
- [db.py](file://backend_core/database/db.py)

**本节来源**
- [realtime.py](file://backend_core/data_collectors/akshare/realtime.py)
- [historical.py](file://backend_core/data_collectors/akshare/historical.py)
- [daily_report_scheduler.py](file://backend_core/scheduler/daily_report_scheduler.py)
- [news_scheduler.py](file://backend_core/schedulers/news_scheduler.py)

## 数据采集器实现

backend_core引擎实现了基于AkShare和Tushare两个数据源的数据采集器，分别负责实时数据和历史数据的采集。

### AkShare数据采集器

AkShare数据采集器通过`akshare`目录下的模块实现，主要包含实时数据采集和历史数据采集两个部分。

#### 实时数据采集

`AkshareRealtimeQuoteCollector`类负责采集股票实时行情数据。该类继承自`AKShareCollector`基类，实现了`collect_quotes`方法来获取实时行情数据。

```mermaid
classDiagram
class AKShareCollector {
+config : Dict[str, Any]
+logger : Logger
+__init__(config : Dict[str, Any])
+_setup_logging()
+_retry_on_failure(func : Callable, *args, **kwargs)
+get_stock_list() DataFrame
+get_realtime_quotes(stock_codes : List[str]) DataFrame
+get_historical_quotes(stock_code : str, start_date : str, end_date : str) DataFrame
+get_fundamental_data(stock_code : str) Dict[str, Any]
+save_data(data : Union[DataFrame, Dict], filepath : Union[str, Path])
}
class AkshareRealtimeQuoteCollector {
+db_file : Path
+__init__(config : Dict[str, Any])
+_init_db() bool
+_safe_value(val : Any) Optional[float]
+collect_quotes() bool
}
AkshareRealtimeQuoteCollector --|> AKShareCollector : 继承
```

**图示来源**
- [realtime.py](file://backend_core/data_collectors/akshare/realtime.py)
- [base.py](file://backend_core/data_collectors/akshare/base.py)

**本节来源**
- [realtime.py](file://backend_core/data_collectors/akshare/realtime.py)
- [base.py](file://backend_core/data_collectors/akshare/base.py)

#### 历史数据采集

`HistoricalQuoteCollector`类负责采集指定日期的历史行情数据。该类同样继承自`AKShareCollector`基类，实现了`collect_quotes`方法来获取历史行情数据。

```mermaid
classDiagram
class AKShareCollector {
+config : Dict[str, Any]
+logger : Logger
+__init__(config : Dict[str, Any])
+_setup_logging()
+_retry_on_failure(func : Callable, *args, **kwargs)
+get_stock_list() DataFrame
+get_realtime_quotes(stock_codes : List[str]) DataFrame
+get_historical_quotes(stock_code : str, start_date : str, end_date : str) DataFrame
+get_fundamental_data(stock_code : str) Dict[str, Any]
+save_data(data : Union[DataFrame, Dict], filepath : Union[str, Path])
}
class HistoricalQuoteCollector {
+db_file : Path
+should_stop : bool
+__init__(config : Dict[str, Any])
+_setup_signal_handlers()
+_signal_handler(signum, frame)
+_init_db() bool
+_safe_value(val : Any) Optional[float]
+_fetch_stock_data(code : str, date_str : str) DataFrame
+collect_quotes(date_str : str) Tuple[int, int]
}
HistoricalQuoteCollector --|> AKShareCollector : 继承
```

**图示来源**
- [historical.py](file://backend_core/data_collectors/akshare/historical.py)
- [base.py](file://backend_core/data_collectors/akshare/base.py)

**本节来源**
- [historical.py](file://backend_core/data_collectors/akshare/historical.py)
- [base.py](file://backend_core/data_collectors/akshare/base.py)

### Tushare数据采集器

Tushare数据采集器通过`tushare`目录下的模块实现，同样包含实时数据采集和历史数据采集两个部分。

#### 实时数据采集

`RealtimeQuoteCollector`类负责通过Tushare接口采集实时行情数据。

```mermaid
classDiagram
class TushareCollector {
+config : Dict[str, Any]
+logger : Logger
+__init__(config : Dict[str, Any])
+_setup_logging()
+_retry_on_failure(func : Callable, *args, **kwargs)
}
class RealtimeQuoteCollector {
+db_file : Path
+__init__(config : Dict[str, Any])
+_init_db() bool
+_safe_value(val : Any) Optional[float]
+collect_quotes() bool
}
RealtimeQuoteCollector --|> TushareCollector : 继承
```

**图示来源**
- [tushare/realtime.py](file://backend_core/data_collectors/tushare/realtime.py)
- [tushare/base.py](file://backend_core/data_collectors/tushare/base.py)

**本节来源**
- [tushare/realtime.py](file://backend_core/data_collectors/tushare/realtime.py)

#### 历史数据采集

`HistoricalQuoteCollector`类负责通过Tushare接口采集历史行情数据，并在数据采集完成后自动计算扩展涨跌幅（5日、10日、60日）。

```mermaid
classDiagram
class TushareCollector {
+config : Dict[str, Any]
+logger : Logger
+__init__(config : Dict[str, Any])
+_setup_logging()
+_retry_on_failure(func : Callable, *args, **kwargs)
}
class HistoricalQuoteCollector {
+__init__(config : Dict[str, Any])
+_init_db() bool
+_safe_value(val : Any) Optional[float]
+extract_code_from_ts_code(ts_code : str) str
+collect_historical_quotes(date_str : str) bool
}
HistoricalQuoteCollector --|> TushareCollector : 继承
```

**图示来源**
- [tushare/historical.py](file://backend_core/data_collectors/tushare/historical.py)
- [tushare/base.py](file://backend_core/data_collectors/tushare/base.py)

**本节来源**
- [tushare/historical.py](file://backend_core/data_collectors/tushare/historical.py)

## 定时任务调度机制

backend_core引擎通过`scheduler`和`schedulers`目录中的模块实现定时任务调度机制。

### 日报生成调度

`DailyReportScheduler`类负责每日报告的生成和发送。该类使用`schedule`库来安排定时任务，在每天上午9:30和下午15:30发送每日股票报告。

```mermaid
sequenceDiagram
participant Scheduler as "DailyReportScheduler"
participant DB as "DatabaseManager"
participant Report as "CSVReportGenerator"
participant WeChat as "WeChatService"
Scheduler->>DB : get_active_users()
DB-->>Scheduler : 用户列表
Scheduler->>Scheduler : 遍历用户
loop 每个用户
Scheduler->>Report : generate_summary_report(user_id)
Report-->>Scheduler : 报告文件路径
Scheduler->>WeChat : send_file_message(用户, 文件)
WeChat-->>Scheduler : 发送结果
alt 发送成功
Scheduler->>Scheduler : 记录成功
else 发送失败
Scheduler->>Scheduler : 记录失败
end
Scheduler->>Scheduler : 清理临时文件
end
Scheduler->>Scheduler : 输出统计结果
```

**图示来源**
- [daily_report_scheduler.py](file://backend_core/scheduler/daily_report_scheduler.py)

**本节来源**
- [daily_report_scheduler.py](file://backend_core/scheduler/daily_report_scheduler.py)

### 资讯采集调度

`news_scheduler.py`模块负责资讯采集的定时任务，包括市场新闻采集、热门资讯更新和旧新闻清理。

```mermaid
flowchart TD
Start([启动]) --> Setup["设置定时任务"]
Setup --> ScheduleNews["每30分钟采集市场新闻"]
Setup --> ScheduleHot["每小时更新热门资讯"]
Setup --> ScheduleCleanup["每天凌晨2点清理旧新闻"]
Setup --> ExecuteNow["立即执行一次采集"]
ExecuteNow --> RunLoop["运行定时任务循环"]
RunLoop --> CheckPending["检查待执行任务"]
CheckPending --> Sleep["等待60秒"]
Sleep --> CheckPending
CheckPending --> KeyboardInterrupt["收到中断信号?"]
KeyboardInterrupt --> |是| Exit["退出程序"]
KeyboardInterrupt --> |否| CheckPending
```

**图示来源**
- [news_scheduler.py](file://backend_core/schedulers/news_scheduler.py)

**本节来源**
- [news_scheduler.py](file://backend_core/schedulers/news_scheduler.py)

## 核心数据模型

backend_core引擎在`models`目录中定义了核心数据模型，主要包括历史行情和自选股列表。

### 历史行情数据模型

`HistoricalQuotes`类定义了历史行情数据的结构，映射到数据库中的`historical_quotes`表。

```mermaid
erDiagram
HISTORICAL_QUOTES {
string code PK
string ts_code
string name
string market
date date PK
float open
float high
float low
float close
float pre_close
integer volume
float amount
float amplitude
float change_percent
float change
float turnover_rate
string collected_source
datetime collected_date
}
```

**图示来源**
- [historical_quotes.py](file://backend_core/models/historical_quotes.py)

**本节来源**
- [historical_quotes.py](file://backend_core/models/historical_quotes.py)

### 自选股数据模型

`Watchlist`类定义了自选股列表的结构，映射到数据库中的`watchlist`表。

```mermaid
erDiagram
WATCHLIST {
integer id PK
integer user_id
string stock_code
string stock_name
string group_name
datetime created_at
}
```

**图示来源**
- [watchlist.py](file://backend_core/models/watchlist.py)

**本节来源**
- [watchlist.py](file://backend_core/models/watchlist.py)

## 配置注入机制

backend_core引擎通过`config.py`文件实现配置注入机制，支持多环境部署。

### 配置结构

配置文件定义了项目根目录、数据库目录以及Tushare和数据采集器的具体配置。

```mermaid
classDiagram
class Config {
+ROOT_DIR : Path
+DB_DIR : Path
+TUSHARE_CONFIG : Dict[str, Any]
+DATA_COLLECTORS : Dict[str, Any]
}
class DataCollectorsConfig {
+tushare : Dict[str, Any]
+akshare : Dict[str, Any]
}
class TushareConfig {
+max_retries : int
+retry_delay : int
+timeout : int
+log_dir : str
+db_file : str
+max_connection_errors : int
+token : str
}
class AkshareConfig {
+max_retries : int
+retry_delay : int
+timeout : int
+log_dir : str
+db_file : str
+max_connection_errors : int
}
Config "1" *-- "1" DataCollectorsConfig : 包含
DataCollectorsConfig "1" *-- "1" TushareConfig : tushare
DataCollectorsConfig "1" *-- "1" AkshareConfig : akshare
```

**图示来源**
- [config.py](file://backend_core/config/config.py)

**本节来源**
- [config.py](file://backend_core/config/config.py)

## 与backend_api的集成

backend_core核心引擎可以被backend_api调用，也可以独立运行数据采集任务。

### 核心引擎调用流程

```mermaid
sequenceDiagram
participant API as "backend_api"
participant Core as "backend_core"
participant Collector as "数据采集器"
participant DB as "数据库"
API->>Core : 调用数据采集方法
Core->>Collector : 初始化采集器
Collector->>Collector : 验证配置
Collector->>Collector : 初始化数据库
Collector->>AkShare : 调用API获取数据
AkShare-->>Collector : 返回数据
Collector->>DB : 存储数据
DB-->>Collector : 存储结果
Collector->>Core : 返回采集结果
Core-->>API : 返回结果
```

**本节来源**
- [realtime.py](file://backend_core/data_collectors/akshare/realtime.py)
- [historical.py](file://backend_core/data_collectors/akshare/historical.py)
- [main.py](file://backend_core/data_collectors/main.py)

## 数据采集失败处理与重试机制

backend_core引擎实现了完善的数据采集失败处理和重试机制。

### 重试机制实现

`AKShareCollector`基类中的`_retry_on_failure`方法实现了通用的重试机制，支持配置最大重试次数和重试延迟。

```mermaid
flowchart TD
Start([开始]) --> TryCall["尝试调用函数"]
TryCall --> Success{"调用成功?"}
Success --> |是| ReturnResult["返回结果"]
Success --> |否| CheckRetries["检查重试次数"]
CheckRetries --> MaxRetries{"达到最大重试次数?"}
MaxRetries --> |是| RaiseException["抛出异常"]
MaxRetries --> |否| Wait["等待retry_delay秒"]
Wait --> TryCall
ReturnResult --> End([结束])
RaiseException --> End
```

**图示来源**
- [base.py](file://backend_core/data_collectors/akshare/base.py)

**本节来源**
- [base.py](file://backend_core/data_collectors/akshare/base.py)

### 数据库操作重试

在处理数据库操作时，特别是插入操作，引擎实现了针对锁冲突和死锁的重试机制。

```mermaid
flowchart TD
Start([开始]) --> InsertData["尝试插入数据"]
InsertData --> Success{"插入成功?"}
Success --> |是| UpdateCounter["更新计数器"]
Success --> |否| CheckError["检查错误类型"]
CheckError --> IsLockError{"是锁冲突或死锁?"}
IsLockError --> |是| IncrementRetry["重试次数+1"]
IsLockError --> |否| LogError["记录错误并继续"]
IncrementRetry --> CheckMaxRetries["检查是否达到最大重试次数"]
CheckMaxRetries --> MaxRetries{"达到最大重试次数?"}
MaxRetries --> |是| LogFailure["记录失败并继续"]
MaxRetries --> |否| Wait["等待递增时间"]
Wait --> InsertData
UpdateCounter --> NextRecord["处理下一条记录"]
LogError --> NextRecord
LogFailure --> NextRecord
NextRecord --> HasMore{"还有更多记录?"}
HasMore --> |是| InsertData
HasMore --> |否| End([结束])
```

**本节来源**
- [realtime.py](file://backend_core/data_collectors/akshare/realtime.py)
- [tushare/historical.py](file://backend_core/data_collectors/tushare/historical.py)

## 性能监控实现

backend_core引擎通过多种方式实现性能监控。

### 数据库连接优化

在`db.py`文件中，数据库连接配置包含了多项性能优化参数：

```python
engine = create_engine(
    DATABASE_URL, 
    echo=False,
    pool_size=10,
    max_overflow=20,
    pool_pre_ping=True,
    pool_recycle=3600,
    connect_args={
        "options": "-c deadlock_timeout=1s -c lock_timeout=5s -c statement_timeout=30s"
    }
)
```

这些配置参数包括：
- **连接池大小**: 10个连接
- **最大溢出连接数**: 20个
- **连接前ping检查**: 确保连接有效性
- **连接回收时间**: 3600秒
- **死锁超时**: 1秒
- **锁超时**: 5秒
- **语句超时**: 30秒

```mermaid
graph TD
A[应用请求] --> B{连接池有空闲连接?}
B --> |是| C[使用空闲连接]
B --> |否| D{连接数<最大连接数?}
D --> |是| E[创建新连接]
D --> |否| F{有溢出连接?}
F --> |是| G[使用溢出连接]
F --> |否| H[等待空闲连接]
C --> I[执行数据库操作]
E --> I
G --> I
H --> I
I --> J[返回结果]
```

**图示来源**
- [db.py](file://backend_core/database/db.py)

**本节来源**
- [db.py](file://backend_core/database/db.py)

### 日志监控

引擎通过详细的日志记录来监控性能和错误情况。每个采集器都有独立的日志文件，记录关键操作的执行情况。

```mermaid
flowchart TD
Start([开始采集]) --> LogStart["记录开始日志"]
LogStart --> GetData["获取数据"]
GetData --> CheckData["检查数据是否为空"]
CheckData --> |数据为空| LogError["记录错误日志"]
CheckData --> |数据不为空| ProcessData["处理数据"]
ProcessData --> InsertDB["插入数据库"]
InsertDB --> CheckInsert["检查插入结果"]
CheckInsert --> |成功| LogSuccess["记录成功日志"]
CheckInsert --> |失败| HandleError["处理错误"]
HandleError --> Retry["重试机制"]
Retry --> CheckMaxRetries["检查最大重试次数"]
CheckMaxRetries --> |达到上限| LogFinalError["记录最终错误"]
CheckMaxRetries --> |未达到上限| Wait["等待后重试"]
LogSuccess --> End["结束"]
LogFinalError --> End
LogError --> End
```

**本节来源**
- [realtime.py](file://backend_core/data_collectors/akshare/realtime.py)
- [historical.py](file://backend_core/data_collectors/akshare/historical.py)