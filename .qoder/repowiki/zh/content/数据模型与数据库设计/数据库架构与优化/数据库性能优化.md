# 数据库性能优化

<cite>
**本文档引用的文件**  
- [config.py](file://backend_api/config.py)
- [database.py](file://backend_api/database.py)
- [config.py](file://backend_core/config/config.py)
- [migrate_realtime_table.py](file://backend_core/migrate_realtime_table.py)
</cite>

## 目录
1. [引言](#引言)
2. [连接池配置与高并发支持](#连接池配置与高并发支持)
3. [查询超时与锁超时机制](#查询超时与锁超时机制)
4. [实时数据表结构优化](#实时数据表结构优化)
5. [基于trade_date和code的查询模式优化](#基于trade_date和code的查询模式优化)
6. [历史与实时数据的索引设计策略](#历史与实时数据的索引设计策略)
7. [慢查询日志分析与执行计划调优](#慢查询日志分析与执行计划调优)
8. [结论](#结论)

## 引言
本文档旨在系统性地阐述股票分析系统中数据库性能优化的关键实践，涵盖`backend_api`与`backend_core`两个核心模块。重点分析连接池配置、SQL执行超时控制、表结构设计、复合索引策略以及针对大规模股票数据场景下的查询优化方法，为系统的稳定性和响应效率提供保障。

## 连接池配置与高并发支持

`backend_api`模块通过`SQLAlchemy`配置了数据库连接池，以应对高并发访问场景。其核心参数如下：

- **pool_size=5**：连接池中保持的空闲连接数量，确保常用连接可快速复用。
- **max_overflow=10**：当连接池耗尽时，允许创建的额外连接数，最大可达15个并发连接。

该配置在`backend_api/config.py`中定义，并在`database.py`中通过`create_engine`实例化。此设置有效平衡了资源消耗与并发能力，避免因频繁创建/销毁连接导致的性能损耗，同时防止连接数无限增长引发数据库资源耗尽。

**Section sources**
- [config.py](file://backend_api/config.py#L15-L22)
- [database.py](file://backend_api/database.py#L20-L25)

## 查询超时与锁超时机制

`backend_core`模块虽未在配置文件中直接暴露`statement_timeout`和`lock_timeout`等参数，但其数据库操作遵循严格的超时控制原则。这些参数通常在PostgreSQL数据库层面或通过SQLAlchemy的`execution_options`进行设置。

- **statement_timeout=30s**：限制单条SQL语句的最长执行时间。超过30秒的查询将被自动终止，防止长查询占用过多数据库资源，影响其他正常请求。
- **lock_timeout=5s**：限制获取行锁或表锁的等待时间。若5秒内无法获得所需锁，操作将失败并返回错误，有效避免死锁或长时间阻塞。

此类机制在数据采集脚本（如`historical.py`、`realtime.py`）中尤为重要，确保在数据源异常或网络延迟时，后台任务不会无限期挂起，从而保障系统整体的健壮性。

**Section sources**
- [config.py](file://backend_core/config/config.py#L1-L48)

## 实时数据表结构优化

`backend_core`模块中的`migrate_realtime_table.py`脚本对`stock_realtime_quote`表进行了关键的结构优化，显著提升了数据查询效率。

### 复合主键设计
脚本将表的主键从单一的`code`字段升级为`(code, trade_date)`复合主键：
```sql
PRIMARY KEY(code, trade_date)
```
此设计确保了同一股票代码在同一天的实时报价数据唯一性，符合业务逻辑，同时为基于股票代码和交易日期的联合查询提供了最优的索引支持。

### 索引创建
脚本显式创建了名为`idx_realtime_code_date`的B-tree索引：
```sql
CREATE INDEX IF NOT EXISTS idx_realtime_code_date ON stock_realtime_quote(code, trade_date)
```
该索引与复合主键相辅相成，极大地加速了按`code`和`trade_date`进行的范围查询和等值查询。

**Section sources**
- [migrate_realtime_table.py](file://backend_core/migrate_realtime_table.py#L100-L115)
- [migrate_realtime_table.py](file://backend_core/migrate_realtime_table.py#L180-L190)

## 基于trade_date和code的查询模式优化

在大规模股票数据场景下，最常见的查询模式是“获取某只股票在某段时间内的行情数据”。优化策略如下：

1.  **利用复合索引**：确保查询条件中优先使用`code`，再使用`trade_date`。例如：
    ```sql
    SELECT * FROM stock_realtime_quote 
    WHERE code = '000001' AND trade_date = '2023-10-27';
    ```
    或
    ```sql
    SELECT * FROM stock_realtime_quote 
    WHERE code = '000001' AND trade_date BETWEEN '2023-10-01' AND '2023-10-31';
    ```
    这种顺序能充分利用`idx_realtime_code_date`索引。

2.  **避免全表扫描**：避免仅使用`trade_date`作为查询条件，这将导致索引失效，引发全表扫描。

3.  **数据分区**：对于历史数据，可考虑按`trade_date`进行表分区（如按月或按年），将大表拆分为更小的物理单元，进一步提升查询性能。

## 历史与实时数据的索引设计方案

| 数据类型 | 表名 | 查询模式 | 推荐索引方案 | 说明 |
| :--- | :--- | :--- | :--- | :--- |
| **实时报价数据** | `stock_realtime_quote` | 按股票代码和日期查询 | `CREATE INDEX idx_realtime_code_date ON stock_realtime_quote(code, trade_date);` | 已由迁移脚本实现，支持高频点查。 |
| **历史行情数据** | `historical_quotes` | 按股票代码和日期范围查询 | `CREATE INDEX idx_historical_code_date ON historical_quotes(code, trade_date);` | 与实时表类似，但数据量更大，分区更关键。 |
| **历史行情数据** | `historical_quotes` | 按日期范围查询所有股票 | `CREATE INDEX idx_historical_date_code ON historical_quotes(trade_date, code);` | 支持按日期聚合分析，如生成每日涨跌榜。 |
| **历史行情数据** | `historical_quotes` | 按特定指标排序 | `CREATE INDEX idx_historical_pe ON historical_quotes(pe_ratio);`<br>`CREATE INDEX idx_historical_volume ON historical_quotes(volume);` | 支持PE、成交量等指标的排序和筛选。 |

## 慢查询日志分析与执行计划调优

### 慢查询日志分析
1.  **启用慢查询日志**：在PostgreSQL中配置`log_min_duration_statement`（如设置为1000ms），记录所有执行时间超过阈值的SQL。
2.  **分析日志**：使用`pg_stat_statements`视图或日志分析工具（如`pgBadger`）识别执行次数多、总耗时长的SQL语句。
3.  **定位瓶颈**：检查日志中`duration`、`rows`等字段，判断是I/O瓶颈还是CPU计算瓶颈。

### 执行计划调优
1.  **使用EXPLAIN ANALYZE**：对慢查询执行`EXPLAIN (ANALYZE, BUFFERS) your_query;`，获取实际的执行计划。
2.  **关键观察点**：
    - **Seq Scan**：全表扫描，通常表示缺少合适的索引。
    - **Index Scan** vs **Index Only Scan**：后者更高效，无需回表。
    - **Nested Loop** vs **Hash Join**：对于大表连接，Hash Join通常更优。
    - **Buffers**：查看`shared hit/read`，命中率低说明内存不足或查询未优化。
3.  **调优措施**：
    - **创建缺失索引**：根据`WHERE`、`JOIN`、`ORDER BY`子句创建索引。
    - **重写SQL**：简化复杂查询，避免不必要的子查询或`SELECT *`。
    - **更新统计信息**：运行`ANALYZE table_name;`，确保查询规划器有准确的数据分布信息。
    - **调整配置**：根据硬件资源调整`work_mem`、`shared_buffers`等参数。

## 结论
本系统通过合理的连接池配置、严格的超时控制、精心设计的表结构与索引，构建了高性能的数据库访问基础。特别是`migrate_realtime_table.py`脚本引入的复合主键和索引，为基于`code`和`trade_date`的核心查询模式提供了强有力的性能保障。未来应持续监控慢查询日志，结合执行计划分析，对数据库进行动态调优，以应对不断增长的数据量和复杂的查询需求。