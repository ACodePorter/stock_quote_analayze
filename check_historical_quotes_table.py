#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥ historical_quotes è¡¨ç»“æ„å’Œçº¦æŸ
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from backend_core.database.db import SessionLocal, engine
from sqlalchemy import text, inspect
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_historical_quotes_table():
    """æ£€æŸ¥historical_quotesè¡¨ç»“æ„"""
    logger.info("ğŸ” æ£€æŸ¥historical_quotesè¡¨ç»“æ„...")
    
    session = SessionLocal()
    try:
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        result = session.execute(text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = 'historical_quotes'
            );
        """))
        table_exists = result.scalar()
        
        if not table_exists:
            logger.warning("âš ï¸  historical_quotesè¡¨ä¸å­˜åœ¨ï¼")
            return False
        
        # æ£€æŸ¥è¡¨ç»“æ„
        result = session.execute(text("""
            SELECT column_name, data_type, is_nullable, column_default 
            FROM information_schema.columns 
            WHERE table_name = 'historical_quotes' 
            ORDER BY ordinal_position;
        """))
        
        columns = result.fetchall()
        logger.info("ğŸ“‹ historical_quotesè¡¨ç»“æ„:")
        for col in columns:
            logger.info(f"  - {col[0]}: {col[1]} (nullable: {col[2]}, default: {col[3]})")
        
        # æ£€æŸ¥çº¦æŸ
        result = session.execute(text("""
            SELECT conname, contype, pg_get_constraintdef(oid) 
            FROM pg_constraint 
            WHERE conrelid = 'historical_quotes'::regclass;
        """))
        
        constraints = result.fetchall()
        logger.info("ğŸ”’ historical_quotesè¡¨çº¦æŸ:")
        for constraint in constraints:
            logger.info(f"  - {constraint[0]}: {constraint[1]} - {constraint[2]}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸»é”®çº¦æŸ
        has_primary_key = any(c[1] == 'p' for c in constraints)
        logger.info(f"ğŸ”‘ æ˜¯å¦æœ‰ä¸»é”®çº¦æŸ: {has_primary_key}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤–é”®çº¦æŸ
        has_foreign_key = any(c[1] == 'f' for c in constraints)
        logger.info(f"ğŸ”— æ˜¯å¦æœ‰å¤–é”®çº¦æŸ: {has_foreign_key}")
        
        # æ£€æŸ¥ç´¢å¼•
        result = session.execute(text("""
            SELECT indexname, indexdef 
            FROM pg_indexes 
            WHERE tablename = 'historical_quotes';
        """))
        
        indexes = result.fetchall()
        logger.info("ğŸ“Š historical_quotesè¡¨ç´¢å¼•:")
        for index in indexes:
            logger.info(f"  - {index[0]}: {index[1]}")
        
        # æ£€æŸ¥æ•°æ®é‡
        result = session.execute(text("SELECT COUNT(*) FROM historical_quotes"))
        row_count = result.scalar()
        logger.info(f"ğŸ“Š è¡¨æ•°æ®é‡: {row_count} è¡Œ")
        
        # æ£€æŸ¥é‡å¤æ•°æ®
        result = session.execute(text("""
            SELECT code, date, COUNT(*) as count
            FROM historical_quotes 
            GROUP BY code, date 
            HAVING COUNT(*) > 1
            LIMIT 10
        """))
        
        duplicates = result.fetchall()
        if duplicates:
            logger.warning(f"âš ï¸  å‘ç° {len(duplicates)} ç»„é‡å¤æ•°æ®:")
            for dup in duplicates:
                logger.warning(f"  - code: {dup[0]}, date: {dup[1]}, count: {dup[2]}")
        else:
            logger.info("âœ… æœªå‘ç°é‡å¤æ•°æ®")
        
        return has_primary_key, has_foreign_key
        
    except Exception as e:
        logger.error(f"âŒ æ£€æŸ¥è¡¨ç»“æ„å¤±è´¥: {e}")
        return False, False
    finally:
        session.close()

def check_historical_collect_operation_logs_table():
    """æ£€æŸ¥historical_collect_operation_logsè¡¨ç»“æ„"""
    logger.info("ğŸ” æ£€æŸ¥historical_collect_operation_logsè¡¨ç»“æ„...")
    
    session = SessionLocal()
    try:
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        result = session.execute(text("""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = 'historical_collect_operation_logs'
            );
        """))
        table_exists = result.scalar()
        
        if not table_exists:
            logger.warning("âš ï¸  historical_collect_operation_logsè¡¨ä¸å­˜åœ¨ï¼")
            return False
        
        # æ£€æŸ¥è¡¨ç»“æ„
        result = session.execute(text("""
            SELECT column_name, data_type, is_nullable, column_default 
            FROM information_schema.columns 
            WHERE table_name = 'historical_collect_operation_logs' 
            ORDER BY ordinal_position;
        """))
        
        columns = result.fetchall()
        logger.info("ğŸ“‹ historical_collect_operation_logsè¡¨ç»“æ„:")
        for col in columns:
            logger.info(f"  - {col[0]}: {col[1]} (nullable: {col[2]}, default: {col[3]})")
        
        # æ£€æŸ¥çº¦æŸ
        result = session.execute(text("""
            SELECT conname, contype, pg_get_constraintdef(oid) 
            FROM pg_constraint 
            WHERE conrelid = 'historical_collect_operation_logs'::regclass;
        """))
        
        constraints = result.fetchall()
        logger.info("ğŸ”’ historical_collect_operation_logsè¡¨çº¦æŸ:")
        for constraint in constraints:
            logger.info(f"  - {constraint[0]}: {constraint[1]} - {constraint[2]}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸»é”®çº¦æŸ
        has_primary_key = any(c[1] == 'p' for c in constraints)
        logger.info(f"ğŸ”‘ æ˜¯å¦æœ‰ä¸»é”®çº¦æŸ: {has_primary_key}")
        
        return has_primary_key
        
    except Exception as e:
        logger.error(f"âŒ æ£€æŸ¥è¡¨ç»“æ„å¤±è´¥: {e}")
        return False
    finally:
        session.close()

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ£€æŸ¥historical_quotesè¡¨...")
    
    # æ£€æŸ¥historical_quotesè¡¨
    has_pk, has_fk = check_historical_quotes_table()
    
    # æ£€æŸ¥historical_collect_operation_logsè¡¨
    logs_has_pk = check_historical_collect_operation_logs_table()
    
    # æ€»ç»“
    logger.info("""
ğŸ“Š æ£€æŸ¥ç»“æœæ€»ç»“:

historical_quotesè¡¨:
- ä¸»é”®çº¦æŸ: {}
- å¤–é”®çº¦æŸ: {}

historical_collect_operation_logsè¡¨:
- ä¸»é”®çº¦æŸ: {}

ğŸ”§ å»ºè®®:
1. å¦‚æœhistorical_quotesç¼ºå°‘ä¸»é”®çº¦æŸï¼Œéœ€è¦æ·»åŠ : ALTER TABLE historical_quotes ADD CONSTRAINT historical_quotes_pkey PRIMARY KEY (code, date);
2. å¦‚æœhistorical_collect_operation_logsç¼ºå°‘ä¸»é”®çº¦æŸï¼Œéœ€è¦æ·»åŠ : ALTER TABLE historical_collect_operation_logs ADD CONSTRAINT historical_collect_operation_logs_pkey PRIMARY KEY (id);
3. å»ºè®®åˆ›å»ºç´¢å¼•: CREATE INDEX IF NOT EXISTS idx_historical_quotes_code ON historical_quotes(code);
4. å»ºè®®åˆ›å»ºç´¢å¼•: CREATE INDEX IF NOT EXISTS idx_historical_quotes_date ON historical_quotes(date);
    """.format(has_pk, has_fk, logs_has_pk))
    
    logger.info("âœ… æ£€æŸ¥å®Œæˆ")

if __name__ == "__main__":
    main() 